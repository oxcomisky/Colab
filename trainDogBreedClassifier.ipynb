{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"trainDogBreedClassifier.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"mh3IwULItYlB"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tjwTvll4Pvc"},"source":["#userDirectory = \"/content/drive/MyDrive/CS465/CS465_final_project/\"\n","userDirectory = \"C:/Users/seanm/OneDrive - MNSCU/Fall 2021/CS 465/CS465_final_project\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"61YCs5A9AAYL"},"source":["#userDirectory = \"/content/drive/MyDrive/CNN/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ylHXdPkI2lxr"},"source":["#Import Modules"]},{"cell_type":"code","metadata":{"id":"yS_ZpkDH2NeM"},"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import *\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.applications import Xception, DenseNet201, VGG19, ResNet50\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u2ZVY9su2Uon"},"source":["#Helper Functions"]},{"cell_type":"code","metadata":{"id":"ZllU66yy2PHE"},"source":["def build_model(size, num_classes, model_type, aug_input):\n","    import tensorflow as tf\n","    from tensorflow.keras import layers, regularizers\n","    from tensorflow.keras.models import Sequential\n","    from tensorflow.keras.applications import Xception\n","    from tensorflow.keras.layers import Input\n","    from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomContrast\n","    from tensorflow.keras.layers import Dropout, BatchNormalization, GlobalAveragePooling2D, Dense, Flatten\n","\n","    inputs = Input((size, size, 3))\n","\n","    ##Data augmentation layers\n","    data_augmentation = Sequential(\n","       [\n","         RandomFlip(\"horizontal\"),\n","         RandomZoom(0.1),\n","         RandomContrast(0.2)\n","       ]\n","    )\n","    \n","    x = tf.cast(inputs, tf.float32)\n","    if(model_type == \"resnet50\"):\n","        x = tf.keras.applications.resnet50.preprocess_input(x)\n","        backbone = ResNet50(input_tensor=x, include_top=False, weights=\"imagenet\")\n","    elif(model_type == \"xception\"):\n","        x = tf.keras.applications.xception.preprocess_input(x)\n","        backbone = Xception(input_tensor=x, include_top=False, weights=\"imagenet\")\n","    elif(model_type == \"densnet\"):\n","        x = tf.keras.applications.densenet.preprocess_input(x)\n","        backbone = DenseNet201(input_tensor=x, include_top=False, weights=\"imagenet\")\n","    elif(model_type == \"vgg19\"):\n","        x = tf.keras.applications.vgg16.preprocess_input(x)\n","        backbone = VGG19(input_tensor=x, include_top=False, weights=\"imagenet\")\n","        \n","    if(aug_input):\n","        x = data_augmentation(x)\n","    backbone.trainable = False\n","    x = backbone.output\n","    x = Dropout(0.25)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.25)(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(0.25)(x)\n","    x = Dense(1024, activity_regularizer=regularizers.l2())(x)\n","    x = Dropout(0.25)(x)\n","    x = Dense(num_classes, activation=\"softmax\", activity_regularizer=regularizers.l2())(x)\n","    \n","\n","    model = tf.keras.Model(inputs, x)\n","    return model\n","\n","##Reads image, resizes images to size passed in, then converts to a numpy array\n","def read_image(path, size):\n","    import cv2\n","    import numpy as np\n","    image = cv2.imread(path, cv2.IMREAD_COLOR)\n","    image = cv2.resize(image, (size, size))\n","    image = image.astype(np.float32)\n","    return image\n","\n","##decodes x data from utf-8, num_class = number of breeds classified, size = the dimensions of the image\n","##creates a label array with num_class indices, then converts labels to a numpy array as int32\n","def parse_data(x, y):\n","    import numpy as np\n","    x = x.decode()\n","\n","    num_class = 120\n","    size = 224\n","    \n","    image = read_image(x, size)\n","    label = [0] * num_class\n","    label[y] = 1\n","    label = np.array(label)\n","    label = label.astype(np.int32)\n","\n","    return image, label\n","\n","##calls parse_data on x and y passed into the function, then sets the shape of the numpy array\n","##to 224x224x3 for x and 120 for y\n","def tf_parse(x, y):\n","    import numpy as np\n","    import tensorflow as tf\n","    x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n","    x.set_shape((224, 224, 3))\n","    y.set_shape((120))\n","    return x, y\n","\n","##retreives the data from x and y and slices it into a image and label tuple,\n","##the dataset is then mapped with the converted information and broken up into *batch* number of batches\n","def tf_dataset(x, y, batch):\n","    import tensorflow as tf\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.map(tf_parse)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.repeat()\n","    return dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTE_uMc_2Xp1"},"source":["#Build & Train Model"]},{"cell_type":"code","metadata":{"id":"buHLEPsb2Dvy"},"source":["##Paths are established to be used via glob later on\n","path = userDirectory\n","train_path = os.path.join(path, \"datasets/Images/**/*\")\n","labels_path = os.path.join(path, \"datasets/labels_full.csv\")\n","\n","##using pandas to read in the csv of labels as a dataframe\n","labels_df = pd.read_csv(labels_path)\n","##breed is established as a dataframe of all 120 unique dog breeds we are going to classify\n","breed = labels_df[\"breed\"].unique()\n","##print number of breeds to verify\n","print(\"Number of Breed: \", len(breed))\n","##convert breed names to integers\n","breed2id = {name: i for i, name in enumerate(breed)}\n","##ids is a list of all image paths in the training set\n","ids = glob(train_path)\n","##labels array is created\n","labels = []\n","\n","##each element in ids is parsed so that the file extensions and preceding pathnames are removed\n","##then each image is paired with its respective breed as an integer\n","for image_id in ids:\n","    image_id = image_id.replace(\"\\\\\",\"/\")\n","    image_id = image_id.split(\"/\")[-1].split(\".\")[0].split(\"-\")[0]\n","    breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])[0]\n","    breed_idx = breed2id[breed_name]\n","    labels.append(breed_idx)\n","\n","## Spliting the dataset\n","train_x, valid_x = train_test_split(ids, test_size=0.1, random_state=0)\n","train_y, valid_y = train_test_split(labels, test_size=0.1, random_state=0)\n","\n","\n","## Parameters\n","size = 224\n","num_classes = 120\n","lr = 1e-2#1e-1\n","batch = 64\n","epochs = 20\n","\n","### Model\n","##specify \"densenet\", \"xception\", \"vgg19\", or \"resnet50\"\n","##specify whether to use image aug or not\n","model = build_model(size, num_classes, model_type=\"densenet\", aug_input=False)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr), metrics=[\"acc\"])\n","# for layer in model:\n","#    layer.trainable = True\n","##uncomment next line to see the structure of the model\n","# model.summary()\n","\n","## convert lists to tf Datasets\n","train_dataset = tf_dataset(train_x, train_y, batch=batch)\n","valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n","\n","##sets the path in which to save the model (we mostly want this to use the weights for further training)\n","callbackFileName = os.path.join(path, \"datasets/DenseNet201.h5\")\n","checkpoint_path = callbackFileName\n","##uncomment next line and run again to load previous weights\n","model.load_weights(checkpoint_path)\n","\n","## Training\n","callbacks = [\n","      ModelCheckpoint(checkpoint_path, verbose=1, save_best_only=True),\n","      #this will reduce the learning rate in case of a dropoff in validation loss\n","      ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, min_lr=1e-6,verbose=1),\n","      #this will stop the model from training if the validation lass does not improve after 5 epochs\n","      EarlyStopping(monitor=\"val_loss\",patience=5, verbose=1)\n","]\n","train_steps = (len(train_x)//batch) + 1\n","valid_steps = (len(valid_x)//batch) + 1\n","#saves the training metrics to a variable to be plotted later\n","history = model.fit(train_dataset,\n","    steps_per_epoch=train_steps,\n","    validation_steps=valid_steps,\n","    validation_data=valid_dataset,\n","    epochs=epochs,\n","    callbacks=callbacks)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YMUvcw4f2oJf"},"source":["#Plot Data"]},{"cell_type":"code","metadata":{"id":"zMRn1ByU2cvA"},"source":["import matplotlib.pyplot as plt\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validate'], loc='upper left')\n","plt.minorticks_on()\n","plt.ylim((0,1.1))\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validate'], loc='upper left')\n","plt.minorticks_on()\n","plt.ylim(0,10)\n","plt.show()"],"execution_count":null,"outputs":[]}]}